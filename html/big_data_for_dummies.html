<!DOCTYPE html>
<html>
<head>
	<title>Big Data for Dummies</title>
</head>
<body>

	<!-- Header part -->
	<header>
		<hgroup>
			<h1 id="Heading">Big Data for Dummies</h1>
			<h3 id="Sub-heading">Leverage big data tools and architecture and How to apply it to make better decisions, especially in business field</h3>
		</hgroup>

		<nav id="main-nav">
			<ul>
				<!-- Part I -->
				<li>
					<a href="#part-I">Part I: Getting Started with Big Data</a>
					<ul>
						<li><a href="#chapter-1">Chapter 1: Grasping the Fundamentals of Big Data</a></li>
						<li><a href="#chapter-2">Chapter 2: Examining Big Data Types</a></li>
						<li><a href="#chapter-3">Chapter 3: Old Meets New: Distributed Computing</a></li>
					</ul>
				<!-- End of Part I -->

				<!-- Part II -->
				<li>
					<a href="#part-II">Part II</a>
					<ul>
						<li><a href="#chapter-4">Chapter 4: Digging into Big Data Technology Components</a></li>
						<li><a href="#chapter-5">Chapter 5: Virtualization and How it supports Distributed Computing</a></li>
						<li><a href="#chapter-6">Chapter 6: Examining the Cloud and Big Data</a></li>
					</ul>
				<!-- End of Part II -->

				<!-- Part III -->
				<li>
					<a href="#part-III">Part III</a>
					<ul>
						<li><a href="#chapter-7">Chapter 7: Operational Databases</a></li>
						<li><a href="#chapter-8">Chapter 8: MapReduce Fundamentals</a></li>
						<li><a href="#chapter-9">Chapter 9: Exploring the World of Hadoop</a></li>
						<li><a href="#chapter-10">Chapter 10: The Hadoop Foundation and Ecosystem</a></li>
						<li><a href="#chapter-11">Chapter 11: Appliances and Big Data Warehouses</a></li>
					</ul>
				<!-- End of Part III -->
			</ul>
		</nav>
	</header>
	<!-- End of Header part -->

	<!-- Main part -->
	<main>

		<!-- Part I Content -->
		<article class="part-content">
			<header>
				<h2 id="part-I">Part I: Getting started with Big Data</h2><hr>
				<ul>In Part I ...
					<li>Trace the evolution of data management</li>
					<li>Define big data and its technology components</li>
					<li>Understand the different types of big data</li>
					<li>Integrate structured and unstructured data</li>
					<li>Understand the difference between real-time and non real-time data</li>
					<li>Scale your big data operation with distributed computing</li>
				</ul>
			</header>

			<!-- Chapter 1 -->
			<article id="chapter-1">
				<header>
					<h3>Chapter 1: Grasping the Fundamentals of Big Data</h3>
					<ul>In Chapter 1 ...
						<li>Looking at a history of data management</li>
						<li>Understanding why big data matters to business</li>
						<li>Applying big data to business effectiveness</li>
						<li>Defining the foundational elements of big data</li>
						<li>Examining bid data's role in the future</li>
					</ul>
				</header>

				<!-- Scenario -->
				<section class="scenario">
					<h4>Scenario</h4>
					<ul>
						<li>Emergence of structured data and unstructured data make data management become harder and out of control</li>
						<li>There are various sources of data generated by machine (sensors), human (social media), and website interactions (click-stream)</li>
						<li>Companies want to make sense of the intersection of all theses different types of data, in order to make better decision</li>
					</ul>
				</section>

				<!-- Definitions -->
				<section class="definition">
					<h4>Definition</h4>
					<ul>
						<li>Big data
							<p>Big data is a combination of old and new technologies that helps companies gian actionable insight.</p>
							<p>Big data is the capability to manage a huge volume of disparate data, at the right speed, and within the right time frame to allow real-time analysis and reaction.</p>
							<ul>Characteristics
								<li>Large Volumes of data</li>
								<li>High Velocity of data</li>
								<li>Wide Variety of data</li>
								<li>Require Veracity of data</li>
							</ul>
						</li>
					</ul>
				</section>
				<!-- End of Definitions -->

				<!-- Causality Relationship -->
				<section class="causality-relationship">
					<h4>Causality Relationship</h4>
					<p><span class="cause">Problem: </span>Data was stored in flat files without any structure</p>
					<p><span class="effect">Solution: </span>Relational data model and relational database anagement system emerged that imposed structure</p><br />

					<p><span class="cause">Problem: </span>The increasing volume of data resulted in high cost and low performance (slow access, duplicated data)</p>
					<p><span class="effect">Solution: </span>Entity Relationship (ER) model emerged</p><br />

					<p><span class="cause">Problem: </span>Data needed to manage grew out of control</p>
					<p><span class="effect">Solution: </span>Data warehouse emerged - analyze subset of large amounts of structured to focus on a particular area of the business</p><br />

					<p><span class="cause">Problem: </span>Data warehouse is too complex and large</p>
					<p><span class="effect">Solution: </span>Data marts emerged that focused on specific business issues</p><br />

					<p><span class="cause">Problem: </span>Huge volumes of unstructured or semi-structured data</p>
					<p><span class="effect">Solution: </span>Object database management stored the <abbr title="Binary Large Objects">BLOB</abbr> as an addressable set of pieces</p><br />

					<p><span class="cause">Cause: </span>A convergence of factors including web, virtualization and cloud computing</p>
					<p><span class="effect">Effect: </span>Require to focus on managing data sources with an unprecedented amount and variety of data with an unheard-of speed</p><br />

					<p><span class="cause">Cause: </span>Cost of computing cycle and storage has reached a tipping point</p>
					<p><span class="effect">Effect: </span>Capability of storing everything needed for analyzing instead of storing snapshots</p>

				</section>
				<!-- End of Problems-Solutions -->

				<!-- Architecture -->
				<section class="architecture">
					<h4>Architecture</h4>
					<ul>
						<li>Cycle of big data management:
							<ul>
								<li>Capture</li>
								<li>Organize</li>
								<li>Integrate</li>
								<li>Analyze</li>
								<li>Act</li>
							</ul>
						</li>

						<li>Architecture of big data
							<img src="../images/big-data-tech-stack.jpg" alt="Big Data Tech Stack" width="300" height="auto"/>
							<p>Open APIs are will be core to any big data architecture</p>
							<p>Interfaces exist at every level and between every layer of stack</p>
							<ul>
								<li>Redundant physical infrastructure
									<p>Fundamental to the operation and scalability of a big data architecture</p>
									<p>Support an unanticipated volume of data => Distributed File System</p>
									<p>Redundance is important because the requirement of processing different sources (SaaS)</p>
								</li>

								<li>Security infrastructure</li>
								<li>Operational data sources
									<p>Encompass a broader set of data sources: structured data (transactions) and unstructured data (customer and social media data)</p>
									<p>Emerging approaches to data management: document, graph, columnar and geospatial database architecture, referred to NoSQL database</p>
								</li>
							</ul>
						</li>
					</ul>
				</section>
				<!-- End of Architecture -->

				<!-- Technology -->
				<section class="technology">
					<h4>Technology fundamental</h4>
					<ul>
						<li>Virtualization</li>
						<li>Cloud computing</li>
						<li>Parallel processing</li>
						<li>Distributed File System</li>
						<li>In-memory database</li>
						<li>MapReduce
							<p>Designed by Google
							<p>Way of efficiently executing a set of functions against a large amount of data in batch mode</p>
							<p>Map component: distribute tasks across a large number of systems and handle the placement of the tasks to satisfy load balancing and fail-over</p>
							<p>Reduce component: aggregate all the elements back together to provide a result</p>
						</li>

						<li>Big Table
							<p>Developed by Google</p>
							<p>A distributed storage system used to manage highly scalable structured data</p>
							<p>Includes columns, rows and timestamp</p>
						</li>

						<li>Hadoop
							<p>An Apache managed software framework derived from MapReduce and Big Table</p>
							<p>Two main components: a massively scalable distributed file system and a massively scalable MapReduce engine that computes results in batch</p>
						</li>
					</ul>
				</section>
				<!-- End of Techonology -->
			</article>
			<!-- End of Chapter 1 -->

			<!-- Chapter 2 -->
			<article id="chapter-2">
				<header>
					<h3>Chapter 2: Examining Big Data Types</h3>
					<ul>In Chapter 2 ...
						<li>Identifying structured and unstructured data</li>
						<li>Recognizing real-time and non-real-time requirements for data types</li>
						<li>Integrating data types into a big data environment</li>
					</ul>
				</header>

				<!-- Definitions -->
				<section class="definition">
					<h4>Definition</h4>
					<ul>
						<!-- Structured data -->
						<li>Structured data
							<ul>
								<li>Data that has a defined length and format</li>
								<li>Stored in database</li>
								<li>Query using a language such as SQL</li>
								<li>Collect from traditional sources such as CRM (Customer Relationship Management), ERP (Operational Enterprise Resource Planning) data, and finance data</li>
							</ul>
						</li>
						<!-- End of Structured data -->

						<!-- Unstructured data -->
						<li>Unstructured data
							<ul>
								<li>Data that does not follow a specified format</li>
							</ul>
						</li>
						<!-- End of Unstructured data -->

						<!-- Real-time requirement -->
						<li>Real-time requirement
							<ul>
								<li>Low latency: amount of time lag that enables a service to execute in anenvironment</li>
								<li>Scalability: capability to sustain a certain level of performance even under increasing loads</li>
								<li>Versatility: support both structured and unstructured data streams</li>
								<li>Native format: use the data in its native form because transformation takes time and money</li>
							</ul>
						</li>
						<!-- End of Real-time requirement -->

					</ul>
				</section>
				<!-- End of Definitions -->

				<!-- Data Model -->
				<section class="data-model">
					<h4>Data Model</h4>
					<ul>
						<!-- Relational Model -->
						<li>Relational model
							<ul>
								<li>Data is stored in a table</li>
								<li>Contains schema that is structural presentation of what is in the database
									<p>Define table</p>
									<p>Define fields in the table: name, types, constraints</p>
									<p>Define relationships between tables</p>
								</li>
							</ul>
						</li>
						<!-- End of Relational model -->
					</ul>
				</section>
				<!-- End of Data Model -->

				<!-- Data Management System -->
				<section class="data-management-system">
					<h4>Data Management System</h4>
					<ul>
						<!-- Relational Database Management System -->
						<li>Relational Database Management System (RDBMS)
							<p>Difficult to master</p>
							<p>Require system programmers to write custom programs to manipulate the data</p>
						</li>
						<!-- End of Relational Database Management System -->

						<!-- Content Management Systems -->
						<li>Content Management Systems
							<p>Manage complete life cycle of content (web content, document content, other forms media</p>
							<p>Technologies in Enterprise Content Management (ECM) are document management, records management, imaging, workflow management, web content management and collaboration</p>
						</li>
						<!-- End of Content Management Systems -->

						<!-- Integrating data types -->
						<li>Integrating data types into a big data environment
							<p>Connectors: enable to pull data in from various big data sources</p>
							<p>Metadata:the definitions, mappings, and other characteristics used to describe how to find, access, and use a company's data components</p>
						</li>
						<!-- End of Integrating data types -->
					</ul>
				</section>
				<!-- End of Data Management System -->

			</article>
			<!-- End of Chapter 2 -->

			<!-- Chapter 3 -->
			<article id="chapter-3">
				<header>
					<h3>Chapter 3: Old Meets New: Distributed Computing</h3>
					<ul>In Chapter 3...
						<li>Taking a look at distributed computing through the yeart</li>
						<li>Exploring the elements of distributed computing</li>
						<li>Putting distributed computing together with hardware and software adcancements</li>
					</ul>
				</header>

				<!-- Scenario -->
				<section class="scenario">
					<h4>Scenario</h4>
					<ul>
						<li>The changing economics of computing
							<p>The cost of purchase computing and storage resource has decreased dramatically</p>
							<p>Aided by virtualization, commodity servers that could be clustered and blades that could be networked in a rack</p>
							<p>Innovation in software automation solutions that dramatically improved the manageability of these systems</p>
						</li>
						<li>The problem with latency
							<p>Latency is the delay within a system based on delays in execution of a task</p>
							<p>Latency is an issue in every aspect of computing, including communications, data management, system performance</p>
							<p>Distributed computing and parallel processing techniques can make a significant difference in the latency - dynamic scaling and load balancing</p>
						</li>
						<li>Demand meet solutions
							<p>The growth of internet</p>
							<p>Requirement for real-time process and analysis a hugh mounts of data</p>
						</li>
					</ul>
				</section>

				<!-- Definitions -->
				<section class="definition">
					<h4>Definition</h4>
					<ul>
						<li>Distributed computing is a foundational technology that drive the most impotant trend over the past decade, including service orientation, cloud computing, virtualization and big data</li>
						<li>Distributed computing is a techique that allows individual computers to be networked together across geographical areas as though they were a single environment</li>
						<li>There are many implementations but they have a common attribute: they are a group of networked computers that work together to execute a workload or process </li>
						<li>The essential contribution of the emergence of Transmission Control Protocol (TCP) -how to communicate between computers- and Internet Protocol (IP) -how to adress them.</li>
					</ul>
				</section>
				<!-- End of Definitions -->

				<!-- Technology -->
				<section class="technology">
					<h4>Technology fundamental</h4>
					<ul>
						<li>Hadoop</li>
						<li>MapReduce</li>
					</ul>
				</section>
				<!-- End of Techonology -->
			</article>
			<!-- End of Chapter 3 -->
			
		</article>
		<!-- End of Part I Content -->

		<!-- ------------------------------------------------------------------------- -->

		<!-- Part II Content -->
		<article class="part-content">
			<header>
				<h2 id="part-II">Part II: Technology Foundations for Big Data</h2><hr>
				<ul>In Part II ...
					<li>Explain the various elements of the big data stack</li>
					<li>Integrate analytics and applications with big data</li>
					<li>Define virtualization</li>
					<li>Explain how virtualization impacts big data</li>
					<li>Add abstraction to the mix</li>
					<li>Understand the cloud and its role in big data</li>
				</ul>
			</header>

			<!-- Chapter 4 -->
			<article id="chapter-4">
				<header>
					<h3>Chapter 4: Digging into Big Data Technology Components</h3>
					<ul>In Chapter 4 ...
						<li>Introducing the big data stack</li>
						<li>Redundant physical infrastructure</li>
						<li>Security infrastructure</li>
						<li>Interfaces and feeds to and from applications</li>
						<li>Operational databases</li>
						<li>Organizing data services and tools</li>
						<li>Analytical data warehouses</li>
						<li>Introduction to big analytics</li>
						<li>Introduction to big data application</li>
					</ul>
				</header>

				<!-- Scenario -->
				<section class="scenario">
					<h4>Scenario</h4>
				</section>

				<!-- Definitions -->
				<section class="definition">
					<h4>Definition</h4>
				</section>
				<!-- End of Definitions -->

				<!-- Causality Relationship -->
				<section class="causality-relationship">
					<h4>Causality Relationship</h4>
					<p><span class="cause">Problem: </span></p>
					<p><span class="effect">Solution: </span></p><br />
				</section>
				<!-- End of Problems-Solutions -->

				<!-- Architecture -->
				<section class="architecture">
					<h4>Architecture</h4>
					<ul>Big Data Stack
						<!-- Layer 0: Redundant Physical Infrastructure -->
						<li>Layer 0: Redundant Physical Infrastructure

							<ul>
								<li>Performance
									<p>How responsive do you need the system to be?</p>
									<p>Refer to latency</p>
								</li>
								
								<li>Availability
									<p>Do you need a 100% uptime guarantee of service?</p>
									<p>How long can your business wait in the case of a service interruption of failure?</p>
								</li>
								
								<li>Scalability
									<p>How bid does your infrastructure need to be?</p>
									<p>How much disk space is needed today and in the future?</p>
									<p>How much computing power do you need?</p>
								</li>
								
								<li>Flexibility
									<p>How quickly can you add more resources to the infrastructure?</p>
									<p>How quickly can your infrastructure recover from failure</p>
								</li>
									
								<li>Cost
									<p>What can you afford?</p>
								</li>
							</ul>

							<ul>Service level agreements (SLAs) describes specific term for performance, recovery, availability
								<li>Physical redundant networks
									<p>Must have enough capacity to accommodate the anticipated volume and velocity of inbound and outbound data</p>
									<p>Must be elastic</p>
									<p>Refer to the blood in a body</p>
								</li>
								<li>Managing hardware: storage and servers
									<p>Must have sufficient speed and capacity to handle all expected big data capabilities</p>
									<p>Storage refers to the memory and Server like nerve system</p>
								</li>
								<li>Infrastructure operations
									<p>Maintain the integrity of data</p>
									<p>Refer to the brain</p>
								</li>
							</ul>

						</li>
						<!-- End of Layer 0 -->

						<!-- Layer 1: Security Infrastructure -->
						<li>Layer 1: Security Infrastructure

							<ul>
								<li>Data access</li>
								<li>Application access</li>
								<li>Data encryption</li>
								<li>Threat detection</li>
							</ul>

						</li>
						<!-- End of Layer 1 -->

						<!-- Layer 2: Operational Databased -->
						<li>Layer 2: Operational Databases
							<p>At the core of any big data environment</p>
							<p>Contain the collections of data elements relevant to the business</p>
							<p>Must be fast, scalable and rock solid</p>
							<img src="../images/characteristics-of-SQL-and-NoSQL-databases.jpg" alt="Characteristics of SQL and NoSQL Databases" />

							<ul>Relational Databases
								<li>Using SQL to query</li>
								<li>ACID behavior
									<p>Atomicity</p>
									<p>Consistency</p>
									<p>Isolation</p>
									<p>Durability</p>
								</li>
							</ul>
						</li>
						<!-- End of Layer 2 -->

						<!-- Layer 3: Organizing Data Service and Tools -->
						<li>Layer 3: Organizing Data Services and Tools
							<p>Capture, validate, and assemble various big data elements into contextually relevant collections</p>
							<p>An ecosystem of tools and technologies that can be used to gather and assemble data in preparation for further processing</p>
							<p>Provide integration, translation, normalization and scale</p>
						</li>
						<!-- End of Layer 3 -->

						<!-- Layer 4: Analytical Data Warehouses -->
						<li>Layer 4: Analytical Data Warehouses
							<p>Company with data marts to optimize data to help decision makers</p>
							<p>Contains normalized data gathered from various of sources and assembled to facilitate analysis of the business</p>
							<p>Symplify creation of reports and the visualization of disparate data items</p>
							<ul>Classes of tools
								<li>Reporting and dashboards: user-friendly representation of the information from various sources</li>
								<li>Visualization: Highly interactive and dynamic in nature using different techniques: mind maps, heat maps, infographics, and connection diagrams</li>
								<li>Analytics and advanced analytics: process data for human consumption
									<p>What did happen?</p>
									<p>Why did it happen?</p>
									<p>What will happen?</p>
									<p>How to make it happen?</p>
								</li>
							</ul>
						</li>
						<!-- End of Layer 4 -->

					</ul>
				</section>
				<!-- End of Architecture -->

				<!-- Technology -->
				<section class="technology">
					<h4>Technology fundamental</h4>
					<ul>Intefaces and Feeds to and from Applications and the Internet
						<li>Representational State Transfer (REST: mechanism for connecting one web resource to another web resource</li>
						<li>RESTfull API: provides a standardized way to create a temporary relationship (loose coupling) among web resources</li>
						<li>Natural Language Processing (NLP): moethod for interfacing between big data and your aplication programs</li>
						<li>Connector factory: additional layer of abstraction and predictability to the process => Service Oriented Architecture (SOA)</li>
					</ul>

					<ul>Layer 3 technologies
						<li>Distributed file system: decompose data streams and provide scale and storage capacity</li>
						<li>Serialization services: persistent data storage and multilanguage remote procedure calls (RPCs)</li>
						<li>Coordination services: build distributed applications</li>
						<li>Extract, transform and load (ETL): load and convert structured and unstructured data into Hadoop</li>
						<li>Workflow services: schedule jobs and provide a structure for synchronizing process elements across layers</li>
					</ul>
				</section>
				<!-- End of Techonology -->
			</article>
			<!-- End of Chapter 4 -->

			<!-- Chapter 5 -->
			<article id="chapter-5">
				<header>
					<h3>Chapter 5: Virtualization and How It Supports Distributed Computing</h3>
					<ul>In Chapter 5 ...
						<li>Defining virtualization</li>
						<li>Understanding the hypervisor</li>
						<li>Exploring abstraction and virtualization</li>
						<li>Implementing virtualization to work with big data</li>
					</ul>
				</header>

				<!-- Definitions -->
				<section class="definition">
					<h4>Definition</h4>
					<ul>
						<li>The process of using computer resources to imitate other resources</li>
						<li>Capability to increase IT resource utilization, efficiency, and scalability</li>
						<li>Make server consolidata, help organizations increase the utilization of physical servers and potentially save on infrastructure costs</li>
						<li>Separate resources and services from underlying physically delivery environment => able to create many virtual systems within a single physical system</li>
					</ul>

					<ul>Characteristics support the scalability and operating efficiency required for big data environment
						<li>Partitioning</li>
						<li>Isolation</li>
						<li>Encapsulation</li>
					</ul>
				</section>
				<!-- End of Definitions -->

				<!-- Benefits and Challenges -->
				<section class="benefit-challenge">
					<h4>Causality Relationship</h4>
					<ul>Benefits
						<li>Virtualization of physical resources (servers, storage and networks) enables substantial improvement in the utilization of these resources</li>
						<li>Virtualization enables improved control over the usage and performance of the IT resources</li>
						<li>Virtualization can provide a level of automation and standardization to optimize your computing environment</li>
						<li>Virtualization provides a foundation for cloud computing</li>
					</ul>

					<ul>Challenges
						<li>Must be managed to be secure</li>
						<li>Must manage unused image, or clean garbage</li>
					</ul>
				</section>
				<!-- End of Benefits and Challenges -->

				<!-- Architecture -->
				<section class="architecture">
					<h4>Architecture</h4>
					<img src="../images/architecture-of-virtualization.jpg" alt="Architecture of Virtualization">
				</section>
				<!-- End of Architecture -->

				<!-- Technology -->
				<section class="technology">
					<h4>Technology fundamental</h4>
					<ul>
						<li>Pool of virtual resources</li>
						<li>Server virtualization
							<ul>
								<li>One physical server is partitioned into multiple virtual servers that each run its own application and OS</li>
								<li>Hardware and resources of a machine: RAM, CPU, hard drive, network controller</li>
								<li>Hypervisor is a thin layer of software that manages traffic between the VMs and the physical machine</li>
							</ul>
						</li>
						<li>Application Virtualization
							<ul>
								<li>Application is encapsulated in a way that removes its dependencies from the underlying physical computer system</li>
								<li>Application become manageable and portable</li>
								<li>Most critical applications can receive top priority to draw from pools of available computing and storage as needed</li>
								<li>Text analytics application may run best in a self-contained environment</li>
							</ul>
						</li>
						<li>Network virtualization
							<ul>
								<li>Software-defined networking</li>
								<li>Provides an efficient way to use networking as a pool of connection resources</li>
								<li>Allow to define multilevel of network based on a certain set of performance characteristics and capacity</li>
							</ul>
						</li>
						<li>Processor virtualization
							<ul>
								<li>Optimize the processor and maximize persormance</li>
							</ul>
						</li>
						<li>Memory virtualization
							<ul>
								<li>Decouples memory from the servers</li>
							</ul>
						</li>
						<li>Data virtualization
							<ul>
								<li>Create platform for dynamic linked data services</li>
								<li>Allow data to be easily searched and linked through a unified reference source (consistent form regardless to the underlying physical database</li>
							</ul>
						</li>
						<li>Storage virtualization
							<ul>
								<li>Combine physical storage resources so that they are more effectively shared</li>
								<li>Reduce cost of storage and make it easier to manage data stores</li>
							</ul>
						</li>
						<li>Abstraction
							<ul>
								<li>Key concept in big data</li>
								<li>Minimize the complexity of something by hiding the details and provide only the relevant information</li>
							</ul>
						</li>
					</ul>
				</section>
				<!-- End of Techonology -->

				<!-- Chapter 6 -->
			<article id="chapter-6">
				<header>
					<h3>Chapter 6: Examining the Cloud and Big Data</h3>
					<ul>In Chapter 6 ...
						<li>Defining the cloud</li>
						<li>Examining cloud deployment and delivery models</li>
						<li>Understanding why the cloud is an imperative for big data</li>
						<li>Understanding </li>
					</ul>
				</header>

				<!-- Scenario -->
				<section class="scenario">
					<h4>Scenario</h4>
				</section>

				<!-- Definitions -->
				<section class="definition">
					<h4>Definition</h4>
					<ul>Cloud key points
						<li>Allow users access needed computing and storage resources without interaction of service provider</li>
						<li>Elastic scalability: user can add or remove resources in real time based on changing requirements</li>
						<li>A method of providing a set of shared computing resources: applications, computing, storage, networking, development, deployment platforms and business processes</li>
					</ul>

					<ul>Characteristics
						<li>Scalability</li>
						<li>Elasticity</li>
						<li>Resource pooling</li>
						<li>Self-service</li>
						<li>Often low up-front costs</li>
						<li>Pay as you go</li>
						<li>Fault tolerance</li>
					</ul>
				</section>
				<!-- End of Definitions -->

				<!-- Challenges -->
				<section class="challenge">
					<h4>Challenges</h4>
					<ul>
						<li>Data integrity - provider maintain</li>
						<li>Compliance - provider comply with</li>
						<li>Costs</li>
						<li>Data transport - may get extra costs</li>
						<li>Performance - SLAs</li>
						<li>Data access - what form of secure access control</li>
						<li>Location - Where will data be located? </li>
					</ul>
				</section>
				<!-- End of Challenges -->

				<!-- Architecture -->
				<section class="architecture">
					<h4>Architecture</h4>
					<ul>Cloud deployment models
						<li>Public cloud</li>
						<li>Private cloud</li>
						<li>Hybrid cloud</li>
					</ul>

					<ul>Cloud delivery models
						<li>Infrastructure as a Service (IaaS)</li>
						<li>Platform as a Service (PaaS)</li>
						<li>Software as a Service (SaaS)</li>
						<li>Data as a Service (DaaS)</li>
					</ul>
				</section>
				<!-- End of Architecture -->

				<!-- Provider -->
				<section class="provider">
					<h4>Provider in the Big Data Cloud Market</h4>
					<ul>Amazon
						<li>Elastic Compute Cloud (EC2)</li>
						<li>Elastic MapReduce</li>
						<li>DynamoDB</li>
						<li>Simple Storage Service (S3)</li>
						<li>High Performance Computing (HPC)</li>
						<li>RedShift</li>
					</ul>

					<ul>Google
						<li>Compute Engine</li>
						<li>Big Query</li>
						<li>Prediction API</li>
					</ul>

					<ul>Microsoft Azure</ul>
					<ul>Open Stack
						<li>Open cloud platform</li>
						<li>An open source IaaS initiative build on Ubuntu</li>
					</ul>
				</section>
				<!-- End of Provider -->
			</article>
			<!-- End of Chapter 6-->
			
		</article>
		<!-- End of Part II Content -->

		<!-- ------------------------------------------------------------------------- -->

		<!-- Part III Content -->
		<article class="part-content">
			<header>
				<h2 id="part-III">Part III: Big Data Management</h2><hr>
				<ul>In Part III ...
					<li>Difference databases in the big data world</li>
					<li>Use MapReduce for data analysis</li>
					<li>Understand Hadoop</li>
					<li>Enhance your Hadoop Distributed File System with programming languages and tools</li>
					<li>Develop applications for big data in analytics</li>
					<li>Use applicances in big data management</li>
				</ul>
			</header>

			<!-- Chapter 7 -->
			<article id="chapter-7">
				<header>
					<h3>Chapter 7: Operational Databases</h3>
					<ul>In Chapter 7 ...
						<li>Taking a look at the relational database</li>
						<li>Examining nonrelational and key-value pair databases</li>
						<li>Exploring document and columnar databases</li>
						<li>Getting to know grap and spatial databases</li>
						<li>Pursuing the polyglot</li>
					</ul>
				</header>

				<!-- Database -->
				<section class="database">
					<h4>Different types of database</h4>
					<ul>Relational Database - PostgreSQL
						<li>Open source relational database</li>
						<li>Support many features
							<ul>
								<li>Capability to directly handle "objects" within the relational schema</li>
								<li>Foreign keys</li>
								<li>Triggers</li>
								<li>COmplex queries</li>
								<li>Transactional integrity</li>
								<li>Multiversion concurrency control</li>
							</ul>
						</li>
						<li>Allow to add new capabilities
							<ul>
								<li>Data types</li>
								<li>Operators</li>
								<li>Functions</li>
								<li>Indexing methods</li>
								<li>Procedural languages</li>
							</ul>
						</li>
					</ul>

					<ul>Riak key-value Database
						<li>Fast and scalable implementation of a key-value database</li>
						<li>Lightweight - support high volume environment with fast changing data</li>
						<li>Effective at real-time analysis</li>
						<li>Use "buckets" as an organization mechanism for collection of keys and values</li>
						<li>Peer-to-peer - clusters are resilient and high scalable</li>
						<li>Larger chusters -> better and faster</li>
						<li>Protocol between nodes: Gossip</li>
						<li>Features: Parallel processing, Links and link walking, Search, and Secondary Indexes</li>
						<li>Applications for
							<ul>
								<li>User data for social networks, communities, or gaming</li>
								<li>High-volume, media-rich data gathering and storage</li>
								<li>Caching layers for connecting RDBMS and NoSQL databases</li>
								<li>Mobile applications requiring flexibility and dependability</li>
							</ul>
						</li>
					</ul>

					<ul>MongoDB Document Database
						<li>Composed of databases containing "collection", that is composed of "documents", that is composed of fields</li>
						<li>Collection is indexable</li>
						<li>Return "cursor" - a pointer to the data, offer the option of counting or classifying the data without extracting it</li>
						<li>Features: High-availability and replication, grid-based file system, MapReduce, sharding service and shard key, support ad hoc queries, distributed queries and full-text search</li>
						<li>Applications for
							<ul>
								<li>High-volume content management</li>
								<li>Social networking</li>
								<li>Archiving</li>
								<li>Reak-time analytics</li>
							</ul>
						</li>
					</ul>
				</section>
				<!-- End of Database -->

				<!-- Technology -->
				<section class="technology">
					<h4>Technology</h4>
					<ul>Non-relational database
						<li>Scalability: capability to write data across multiple data stores simultaneously without regard to physical limitations of the underlying infrastructure</li>
						<li>Data and Query model: framework to store data and set of query APIs to intelligently access the data</li>
						<li>Persistence design: difference mechanism used - "in-memory"</li>
						<li>Interface diversity: RESTful APIs, analysis tools and reporting/visualization</li>
						<li>Eventual consistency: BASE (Basically Available, Soft state, and Eventual Consistency)</li>
					</ul>

					<ul>Key-value pair Databases
						<li>Schema-free</li>
						<li>Offer great flexibility and scalability</li>
						<li>Not offer ACID capability</li>
						<li>Require implementers take care data placement, replication, and fault tolerance</li>
						<li>Most of data is stored as string</li>
					</ul>

					<ul>Document Databases
						<li>Two types: a repository for full document-style content (word files, complete web pages) and a database for storing document components for permanent storage as a static entity or dynamic assembly of the parts of a document</li>
						<li>The structure of the documents: JSON or BSON</li>
						<li>Suitable for producing reports which are dynamically assembled from elements that change frequently</li>
						<li></li>
					</ul>
				</section>
				<!-- End of Technology -->

				
			</article>
			<!-- End of Chapter -->
			
		</article>
		<!-- End of Part III Content -->

	</main>
	<!-- End of Main part -->

	<!-- Footer part -->
	<footer>
		
	</footer>
	<!-- End of Footer part -->

</body>
</html>